# Numerai CI-Pipeline

Lean, reproducible training → prediction → submission stack for the Numerai Tournament
![CI](https://github.com/<your-username>/numerai-ci-pipeline/actions/workflows/ci.yml/badge.svg)

---

## 1 · What this repo does

| Stage                                                                                             | What happens                                                                                                                                                                                                        | Files                                                |
| ------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------- |
| **Train**                                                                                         | Two preset XGBoost models (A & B) fit on the *train* slice of Numerai **v5.0** using the *medium* feature-set. Validation metrics (Spearman corr, MAE, Sharpe-proxy) are logged on the official *validation* slice. | `src/trainer.py` + `configs/xgb_*.json`              |
| **Wrap**                                                                                          | Each model is wrapped in a callable `predict(live_features, live_benchmark_models)` and **cloud-pickled** so Numerai’s “model-upload” engine can run it.                                                            | `src/make_model_pickle.py` → `preds/model_xgb_*.pkl` |
| **Submit**                                                                                        | The pickles are uploaded to two Numerai model slots via the API.                                                                                                                                                    | `src/submit.py`                                      |
| **CI / CD**                                                                                       | • **ci.yml** – fast unit tests on every push / PR                                                                                                                                                                   |                                                      |
| • **nightly.yml** – daily 02 : 30 UTC retrain → wrap → submit (manual ‘Run workflow’ button too). | `.github/workflows/`                                                                                                                                                                                                |                                                      |

---

## 2 · Folder layout

```
.
├─ src/                core code
│   ├─ data.py         download parquet & feature lists
│   ├─ trainer.py      two-model training
│   ├─ make_model_pickle.py
│   └─ submit.py
├─ configs/            hyper-param + feature-set JSONs
├─ tests/              mocked unit tests (fast)
├─ models/             *generated by CI* – trained XGB pickles
├─ preds/              *generated by CI* – callable model pickles
└─ .github/workflows/  ci.yml  nightly.yml
```

---

## 3 · Quick-start (local dev)

```bash
git clone https://github.com/<your-username>/numerai-ci-pipeline.git
cd numerai-ci-pipeline
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# Train two models (~3-5 min CPU)
python -m src.trainer

# Wrap each model in Numerai-compatible predict() callable
python -m src.make_model_pickle

# (Optional) local dry-run upload  – requires env-vars below
export NUMERAI_PUBLIC=...
export NUMERAI_SECRET=...
export MODEL_NAME_A=xgb_A
export MODEL_NAME_B=xgb_B
python -m src.submit
```

---

## 4 · Secrets you need (once, in GitHub)

Only the API keys are required now—model‑slot names are hard‑coded inside `src/submit.py` (`MODEL_A = "xgb_A"`, `MODEL_B = "xgb_B"`).

| Secret name      | Where to get it                               |
| ---------------- | --------------------------------------------- |
| `NUMERAI_PUBLIC` | Numerai → Account → **API Keys** (public ID)  |
| `NUMERAI_SECRET` | Numerai → Account → **API Keys** (secret key) |

Add them under **Repo → Settings → Secrets → Actions**.
`nightly.yml` injects them automatically:

```yaml
env:
  NUMERAI_PUBLIC: ${{ secrets.NUMERAI_PUBLIC }}
  NUMERAI_SECRET: ${{ secrets.NUMERAI_SECRET }}
```

> **Note:** If you ever change the slot names in `src/submit.py`, reflect that change in Numerai’s dashboard; no extra secrets are needed.

---

## 5 · Workflows

| File            | Trigger                                   | What it does                                                                                      |
| --------------- | ----------------------------------------- | ------------------------------------------------------------------------------------------------- |
| **ci.yml**      | `push`, `pull_request`                    | ⋅ installs deps  <br>⋅ runs mocked unit tests (no training, no secrets)                           |
| **nightly.yml** | 02 : 30 UTC daily & “Run workflow” button | ⋅ runs tests  <br>⋅ trains models  <br>⋅ builds `model_xgb_*.pkl`  <br>⋅ uploads to Numerai slots |

> **First-time manual run:**
> Actions → *Nightly Numerai Pipeline* → **Run workflow** → pick `main`.
> Check logs for “uploaded … → slot\_name”.

---

## 6 · Config options

| Field          | Meaning                                                            |
| -------------- | ------------------------------------------------------------------ |
| `data_version` | Numerai dataset version (`v4`, `v5.0`, …)                          |
| `feature_set`  | `small`, `medium`, `large` as defined in Numerai’s `features.json` |
| `params`       | Passed directly to `xgboost.XGBRegressor(**params)`                |

Add new configs in `configs/` and list them in `src/trainer.py::train_all()`.

---

## 7 · Tests

```bash
pytest -q
```

*All network / heavy compute is mocked:* CI finishes in ≈ 7 s.

---

## 8 · Extending

* Add LightGBM / CatBoost: create new config JSONs and param-set.
* Hyper-parameter sweeps: plug Optuna into `trainer.py`.
* Feature-engineering: replace `feats = …` with custom column logic.
* Observability: route `structlog` JSON lines to Loki / Grafana.

---

## 9 · License

MIT © 2025 Pranshu Bahadur — Hack away, but give credit.

